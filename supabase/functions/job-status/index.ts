import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { supabase, corsHeaders } from "../_shared/supabase.ts";
import { startMergeWithFFmpeg, checkMergeStatus } from "../_shared/huggingface.ts";

// Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
const MAX_CONSECUTIVE_FAILURES = 5;

// ===== LOGGING =====
function logInfo(msg: string, data?: any) { console.log(`[STATUS] ${msg}`, data || ''); }
function logError(msg: string, err?: any) { console.error(`[STATUS-ERR] ${msg}`, err || ''); }

serve(async (req) => {
  if (req.method === "OPTIONS") return new Response(null, { headers: corsHeaders });

  try {
    // 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù‡Ù…Ø©
    const url = new URL(req.url);
    const pathParts = url.pathname.split("/");
    let jobId = pathParts[pathParts.length - 1] === "job-status" ? null : pathParts[pathParts.length - 1];
    if (!jobId) jobId = url.searchParams.get("job_id");

    if (!jobId) return new Response(JSON.stringify({ error: "Missing job_id" }), { status: 400, headers: corsHeaders });

    // 2. Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
    const { data: job, error } = await supabase.from("jobs").select("*").eq("id", jobId).single();
    if (error || !job) return new Response(JSON.stringify({ error: "Job not found" }), { status: 404, headers: corsHeaders });

    // 3. Ø¬Ù„Ø¨ Ø§Ù„Ø®Ø·ÙˆØ§Øª
    const { data: steps } = await supabase.from("job_steps").select("*").eq("job_id", jobId).order("step_order");
    const mergeStep = steps?.find((s: any) => s.step_name === "media_merge");

    // ===== Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø°ÙƒÙŠ (LAZY START LOGIC) =====
    
    // Ø§Ù„Ø­Ø§Ù„Ø© Ø£: Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ø³Ø¬Ù„Ø© Ù„ÙƒÙ† Ù„Ù… ØªØ¨Ø¯Ø£ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ Ø¨Ø¹Ø¯
    if (job.status === "pending_start" || (mergeStep && mergeStep.status === "pending")) {
      logInfo(`Job ${jobId} needs starting. Attempting to start on HF...`);
      
      try {
        // ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ù„ÙŠØ¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ù†Ù†Ø§ Ù†Ø­Ø§ÙˆÙ„
        await supabase.from("jobs").update({ status: "processing", progress: 5 }).eq("id", jobId);
        await supabase.from("job_steps").update({ status: "processing", output_data: { stage: "starting_server" } }).eq("id", mergeStep.id);

        // Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¨Ø¯Ø¡ (Ù‚Ø¯ ØªØ³ØªØºØ±Ù‚ Ø¨Ø¶Ø¹ Ø«ÙˆØ§Ù†Ù)
        const result = await startMergeWithFFmpeg({
          images: job.input_data.images,
          audio: job.input_data.audio,
          output_format: "mp4"
        });

        // Ø­ÙØ¸ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ
        await supabase.from("job_steps").update({
          output_data: { 
            provider_job_id: result.job_id, 
            provider: "ffmpeg-space",
            stage: "processing" 
          }
        }).eq("id", mergeStep.id);

        logInfo(`Job started successfully on HF: ${result.job_id}`);

      } catch (startError: any) {
        logError("Failed to start job on HF", startError);
        // Ù„Ø§ Ù†ÙØ´Ù„ Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙˆØ±Ø§Ù‹ØŒ Ø±Ø¨Ù…Ø§ ØªÙ†Ø¬Ø­ ÙÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© (Polling Ø§Ù„ØªØ§Ù„ÙŠ)
        // Ù„ÙƒÙ† Ù†Ø¹ÙŠØ¯ Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„ÙŠØ¹Ø±Ù Ø§Ù„Ø³Ø¨Ø¨
        return new Response(JSON.stringify({
          job_id: jobId,
          status: "processing",
          progress: 5,
          is_stuck: true,
          stuck_warning: "Waiting for server to wake up...",
          logs: [{ step: "Initialization", status: "failed", message: `Retrying connection: ${startError.message}` }]
        }), { headers: { ...corsHeaders, "Content-Type": "application/json" } });
      }
    }

    // Ø§Ù„Ø­Ø§Ù„Ø© Ø¨: Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø¯Ø£Øª ÙˆÙ„Ø¯ÙŠÙ†Ø§ Provider ID -> Ù†ØªØ§Ø¨Ø¹ Ø§Ù„Ø­Ø§Ù„Ø© (Normal Polling)
    else if (job.status === "processing" && mergeStep?.output_data?.provider_job_id) {
      const providerId = mergeStep.output_data.provider_job_id;
      const failures = mergeStep.output_data.consecutive_failures || 0;

      try {
        const status = await checkMergeStatus(providerId);
        
        if (status.status === "completed" && status.output_url) {
          // Ø§Ù„Ù†Ø¬Ø§Ø­! ØªØ­Ù…ÙŠÙ„ ÙˆØ­ÙØ¸
          logInfo("Job completed on provider. Downloading...");
          const fileReq = await fetch(status.output_url);
          const buf = await fileReq.arrayBuffer();
          const path = `${jobId}/final.mp4`;
          
          await supabase.storage.from("media-output").upload(path, buf, { contentType: "video/mp4", upsert: true });
          const { data: pub } = supabase.storage.from("media-output").getPublicUrl(path);

          await supabase.from("jobs").update({ status: "completed", progress: 100, output_url: pub.publicUrl }).eq("id", jobId);
          await supabase.from("job_steps").update({ status: "completed", output_data: { output_url: pub.publicUrl } }).eq("id", mergeStep.id);
          
          // ØªØ­Ø¯ÙŠØ« Ø®Ø·ÙˆØ© Ø§Ù„Ù†Ø´Ø± Ø£ÙŠØ¶Ø§Ù‹
          const pubStep = steps?.find((s: any) => s.step_name === "publishing");
          if (pubStep) await supabase.from("job_steps").update({ status: "completed" }).eq("id", pubStep.id);
        } else if (status.status === "processing") {
          // ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
          const prog = 10 + Math.round((status.progress || 0) * 0.8);
          await supabase.from("jobs").update({ progress: prog }).eq("id", jobId);
          // ØªØµÙÙŠØ± Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙØ´Ù„ Ø¹Ù†Ø¯ Ø§Ù„Ù†Ø¬Ø§Ø­
          if (failures > 0) {
             await supabase.from("job_steps").update({ output_data: { ...mergeStep.output_data, consecutive_failures: 0 } }).eq("id", mergeStep.id);
          }
        } else if (status.status === "failed") {
          throw new Error(status.error || "Provider reported failure");
        }

      } catch (pollErr: any) {
        logError("Polling error", pollErr);
        const newFailures = failures + 1;
        
        if (newFailures >= MAX_CONSECUTIVE_FAILURES) {
          await supabase.from("jobs").update({ status: "failed", error_message: pollErr.message }).eq("id", jobId);
          await supabase.from("job_steps").update({ status: "failed", error_message: pollErr.message }).eq("id", mergeStep.id);
        } else {
          await supabase.from("job_steps").update({ 
            output_data: { ...mergeStep.output_data, consecutive_failures: newFailures, last_error: pollErr.message } 
          }).eq("id", mergeStep.id);
        }
      }
    }

    // Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    // Ù†Ø¹ÙŠØ¯ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø«Ø©
    const { data: finalJob } = await supabase.from("jobs").select("*").eq("id", jobId).single();
    const { data: finalSteps } = await supabase.from("job_steps").select("*").eq("job_id", jobId).order("step_order");

    const logs = (finalSteps || []).map((s: any) => ({
      step: s.step_name,
      status: s.status,
      message: s.status === 'completed' ? `âœ… ${s.step_name} Done` : 
               s.status === 'failed' ? `âŒ ${s.error_message || 'Failed'}` : 
               s.output_data?.stage === 'starting_server' ? 'â³ Waking up server...' :
               `ğŸ”„ ${s.status}...`
    }));

    return new Response(JSON.stringify({
      job_id: finalJob.id,
      status: finalJob.status,
      progress: finalJob.progress,
      output_url: finalJob.output_url,
      logs,
      is_complete: finalJob.status === "completed"
    }), { headers: { ...corsHeaders, "Content-Type": "application/json" } });

  } catch (e: any) {
    return new Response(JSON.stringify({ error: e.message }), { status: 500, headers: corsHeaders });
  }
});
