import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2.93.1";
import { supabase, corsHeaders } from "../_shared/supabase.ts";
import { checkMergeStatus, isFFmpegSpaceHealthy } from "../_shared/huggingface.ts";

const MAX_CONSECUTIVE_FAILURES = 20;

// ===== LOGGING =====
function logInfo(message: string, data?: any) {
  console.log(`[JOB-STATUS] ${message}`, data ? JSON.stringify(data, null, 2) : '');
}

function logError(message: string, error?: any) {
  console.error(`[JOB-STATUS] ${message}`, error ? (error instanceof Error ? error.message : JSON.stringify(error)) : '');
}

function logWarning(message: string, data?: any) {
  console.warn(`[JOB-STATUS] ${message}`, data ? JSON.stringify(data, null, 2) : '');
}

// ===== AUTH HELPER =====
async function validateAuth(req: Request): Promise<{ valid: boolean; error?: string }> {
  const authHeader = req.headers.get("Authorization");
  
  const serviceRoleKey = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY");
  if (authHeader === `Bearer ${serviceRoleKey}`) {
    return { valid: true };
  }
  
  if (!authHeader?.startsWith("Bearer ")) {
    return { valid: false, error: "Authorization header required" };
  }
  
  const token = authHeader.replace("Bearer ", "");
  const anonClient = createClient(
    Deno.env.get("SUPABASE_URL")!,
    Deno.env.get("SUPABASE_ANON_KEY")!,
    { global: { headers: { Authorization: authHeader } } }
  );
  
  const { data, error } = await anonClient.auth.getUser(token);
  if (error || !data?.user) {
    return { valid: false, error: "Invalid or expired token" };
  }
  
  return { valid: true };
}

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const auth = await validateAuth(req);
    if (!auth.valid) {
      return new Response(
        JSON.stringify({ error: auth.error }),
        { status: 401, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    const url = new URL(req.url);
    const pathParts = url.pathname.split("/").filter(Boolean);
    const maybeFromPath = pathParts[pathParts.length - 1];

    let jobId: string | null = null;

    if (maybeFromPath && maybeFromPath !== "job-status") {
      jobId = maybeFromPath;
    } else {
      const fromQuery = url.searchParams.get("job_id") || url.searchParams.get("jobId");
      if (fromQuery) jobId = fromQuery;
      else {
        const body = await req.json().catch(() => ({} as any));
        jobId = body?.job_id || body?.jobId || null;
      }
    }

    if (!jobId) {
      return new Response(
        JSON.stringify({ error: "job_id is required" }),
        { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    logInfo(`ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©: ${jobId}`);

    const { data: job, error: jobError } = await supabase
      .from("jobs")
      .select("*")
      .eq("id", jobId)
      .maybeSingle();

    if (jobError) {
      logError(`ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‡Ù…Ø© ${jobId}`, jobError);
      throw new Error(`Failed to fetch job: ${jobError.message}`);
    }

    if (!job) {
      logWarning(`Ø§Ù„Ù…Ù‡Ù…Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: ${jobId}`);
      return new Response(
        JSON.stringify({ error: "Job not found" }),
        { status: 404, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    let { data: steps, error: stepsError } = await supabase
      .from("job_steps")
      .select("*")
      .eq("job_id", jobId)
      .order("step_order");

    if (stepsError) {
      logError(`ÙØ´Ù„ Ø¬Ù„Ø¨ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ù‡Ù…Ø© ${jobId}`, stepsError);
      throw new Error(`Failed to fetch job steps: ${stepsError.message}`);
    }

    // --- MERGE TICK WITH ENHANCED ERROR HANDLING ---
    const mergeStep = (steps || []).find((s: any) => s.step_name === "merge" && s.status === "processing");
    const publishStep = (steps || []).find((s: any) => s.step_name === "publishing");

    const mergeOutput = (mergeStep?.output_data || {}) as any;
    const providerJobId: string | undefined =
      mergeOutput?.provider_job_id || mergeOutput?.providerJobId || mergeOutput?.job_id || mergeOutput?.jobId;

    // Ø¥Ø°Ø§ merge step Ø¬Ø§Ù‡Ø² (pending + ready_for_merge) â†’ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¯Ù…Ø¬
    const mergeReady = mergeStep?.status === "pending" && (mergeStep?.output_data as any)?.ready_for_merge;
    if (mergeReady && job.status === "processing") {
      const mergeData = (mergeStep?.output_data || {}) as any;
      logInfo("ğŸ”€ Ø¨Ø¯Ø¡ Ø§Ù„Ø¯Ù…Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹...", { images: mergeData.image_urls?.length, audio: !!mergeData.audio_url });

      const { startMergeWithFFmpeg } = await import("../_shared/huggingface.ts");
      const merge = await startMergeWithFFmpeg({
        images: mergeData.image_urls,
        audio: mergeData.audio_url,
        output_format: "mp4",
      });

      if (merge.status === "failed") {
        await supabase.from("jobs").update({ status: "failed", error_message: merge.error || "ÙØ´Ù„ Ø§Ù„Ø¯Ù…Ø¬" }).eq("id", jobId);
        return new Response(JSON.stringify({ status: "failed" }), { headers: { ...corsHeaders, "Content-Type": "application/json" } });
      }

      if (merge.output_url) {
        // Ø§ÙƒØªÙ…Ù„ ÙÙˆØ±Ø§Ù‹
        await supabase.from("job_steps").update({ status: "completed", output_data: { output_url: merge.output_url } }).eq("id", mergeStep!.id);
        await supabase.from("jobs").update({ status: "completed", progress: 100, output_url: merge.output_url }).eq("id", jobId);
        logInfo("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø¯Ù…Ø¬ ÙÙˆØ±Ø§Ù‹:", merge.output_url);
        return new Response(JSON.stringify({ status: "completed", output_url: merge.output_url }), { headers: { ...corsHeaders, "Content-Type": "application/json" } });
      }

      if (merge.job_id) {
        await supabase.from("job_steps").update({
          status: "processing",
          output_data: { ...mergeData, provider_job_id: merge.job_id, ready_for_merge: false },
        }).eq("id", mergeStep!.id);
        await updateProgress(jobId, 78);
        logInfo("âœ… merge queued:", merge.job_id);
        return new Response(JSON.stringify({ status: "processing", merge_job_id: merge.job_id }), { headers: { ...corsHeaders, "Content-Type": "application/json" } });
      }
    }

    if (job.status === "processing" && providerJobId && !job.output_url) {
      logInfo(`Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¯Ù…Ø¬ Ù„Ù„Ù…Ù‡Ù…Ø© ${jobId} (Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø²ÙˆØ¯: ${providerJobId})`);

      // Track consecutive failures
      const currentFailures: number = mergeOutput?.consecutive_failures || 0;

      try {
        const providerStatus = await checkMergeStatus(providerJobId);
        logInfo(`Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø²ÙˆØ¯ [${providerJobId}]:`, providerStatus);

        // Success â€“ reset failure counter
        if (providerStatus.status === "processing") {
          const mapped = Math.min(
            89,
            Math.max(
              job.progress || 75,
              75 + Math.round(((providerStatus.progress ?? 0) / 100) * 14)
            )
          );

          await supabase.from("jobs").update({ progress: mapped }).eq("id", jobId);

          if (mergeStep?.id) {
            await supabase
              .from("job_steps")
              .update({
                output_data: {
                  ...(mergeOutput || {}),
                  provider: "ffmpeg-space",
                  provider_job_id: providerJobId,
                  provider_progress: providerStatus.progress,
                  provider_status: providerStatus.status,
                  stage: "processing",
                  consecutive_failures: 0, // Reset on successful check
                  last_check: new Date().toISOString(),
                },
              })
              .eq("id", mergeStep.id);
          }

          logInfo(`âœ“ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…: ${mapped}%`);
        }

        if (providerStatus.status === "failed") {
          const msg = providerStatus.error || "FFmpeg provider merge failed";
          logError(`ÙØ´Ù„ Ø§Ù„Ø¯Ù…Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²ÙˆØ¯ [${providerJobId}]`, msg);

          if (mergeStep?.id) {
            await supabase
              .from("job_steps")
              .update({ 
                status: "failed", 
                error_message: msg, 
                completed_at: new Date().toISOString(),
                output_data: {
                  ...(mergeOutput || {}),
                  provider_error: msg,
                  failed_at: new Date().toISOString(),
                }
              })
              .eq("id", mergeStep.id);
          }

          await supabase
            .from("jobs")
            .update({ status: "failed", error_message: msg })
            .eq("id", jobId);
        }

        if (providerStatus.status === "completed") {
          logInfo(`âœ“âœ“âœ“ Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø¯Ù…Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²ÙˆØ¯ [${providerJobId}] âœ“âœ“âœ“`);

          if (!providerStatus.output_url) {
            throw new Error("Merge completed but no output URL returned");
          }

          const providerOutputUrl = providerStatus.output_url;
          logInfo(`ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ù†: ${providerOutputUrl}`);

          const videoResp = await fetch(providerOutputUrl);
          if (!videoResp.ok) {
            throw new Error(`Failed to download merged video (HTTP ${videoResp.status})`);
          }
          const videoBuffer = await videoResp.arrayBuffer();
          logInfo(`âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (${videoBuffer.byteLength} bytes)`);

          const finalVideoName = `${jobId}/final_video.mp4`;
          const { error: uploadErr } = await supabase.storage
            .from("media-output")
            .upload(finalVideoName, videoBuffer, {
              contentType: "video/mp4",
              upsert: true,
            });

          if (uploadErr) {
            logError(`ÙØ´Ù„ Ø±ÙØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ`, uploadErr);
            throw new Error(`Final video upload failed: ${uploadErr.message}`);
          }

          const { data: publicUrlData } = supabase.storage
            .from("media-output")
            .getPublicUrl(finalVideoName);

          const finalUrl = publicUrlData.publicUrl;
          logInfo(`âœ“ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù…ØªØ§Ø­ Ø¹Ù„Ù‰: ${finalUrl}`);

          if (mergeStep?.id) {
            await supabase
              .from("job_steps")
              .update({
                status: "completed",
                completed_at: new Date().toISOString(),
                output_data: {
                  ...(mergeOutput || {}),
                  provider: "ffmpeg-space",
                  provider_job_id: providerJobId,
                  provider_output_url: providerOutputUrl,
                  output_url: finalUrl,
                  stage: "persisted",
                  consecutive_failures: 0,
                  completed_at: new Date().toISOString(),
                },
              })
              .eq("id", mergeStep.id);
          }

          await supabase
            .from("jobs")
            .update({ 
              status: "completed", 
              progress: 100, 
              output_url: finalUrl, 
              error_message: null 
            })
            .eq("id", jobId);

          if (publishStep?.id && publishStep.status !== "completed") {
            await supabase
              .from("job_steps")
              .update({
                status: "completed",
                started_at: publishStep.started_at || new Date().toISOString(),
                completed_at: new Date().toISOString(),
                output_data: { video_url: finalUrl, publish_results: {} },
              })
              .eq("id", publishStep.id);
          }

          logInfo(`âœ“âœ“âœ“ Ø§Ù„Ù…Ù‡Ù…Ø© ${jobId} Ø§ÙƒØªÙ…Ù„Øª Ø¨Ù†Ø¬Ø§Ø­! âœ“âœ“âœ“`);
        }
      } catch (e) {
        const errorMsg = e instanceof Error ? e.message : String(e);
        logError(`Ø®Ø·Ø£ ÙÙŠ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø¯Ù…Ø¬ [${jobId}]`, e);

        // Increment failure counter
        const newFailures = currentFailures + 1;
        logWarning(`ÙØ´Ù„ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø¯Ù…Ø¬ ${newFailures}/${MAX_CONSECUTIVE_FAILURES} Ù„Ù„Ù…Ù‡Ù…Ø© ${jobId}`, errorMsg);

        // Check if it's a server health issue
        let serverHealthInfo = "";
        try {
          const healthCheck = await isFFmpegSpaceHealthy();
          if (!healthCheck.healthy) {
            serverHealthInfo = `\nØ­Ø§Ù„Ø© Ø§Ù„Ø³ÙŠØ±ÙØ±: ${healthCheck.error || 'ØºÙŠØ± ØµØ­ÙŠ'}`;
            if (healthCheck.isSleeping) {
              serverHealthInfo += "\nâš ï¸ Ø§Ù„Ø³ÙŠØ±ÙØ± ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø³ÙƒÙˆÙ† - Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„";
            }
          }
        } catch (healthError) {
          logWarning('ÙØ´Ù„ ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø³ÙŠØ±ÙØ±', healthError);
        }

        if (mergeStep?.id) {
          await supabase
            .from("job_steps")
            .update({
              output_data: {
                ...(mergeOutput || {}),
                consecutive_failures: newFailures,
                last_error: errorMsg,
                last_error_time: new Date().toISOString(),
                server_health_checked: !!serverHealthInfo,
              },
            })
            .eq("id", mergeStep.id);
        }

        // If too many consecutive failures, fail the job with detailed error
        if (newFailures >= MAX_CONSECUTIVE_FAILURES) {
          const failMsg = 
            `Ø³ÙŠØ±ÙØ± Ø§Ù„Ø¯Ù…Ø¬ Ù„Ø§ ÙŠØ³ØªØ¬ÙŠØ¨ Ø¨Ø¹Ø¯ ${MAX_CONSECUTIVE_FAILURES} Ù…Ø­Ø§ÙˆÙ„Ø© ÙØ§Ø´Ù„Ø© Ù…ØªØªØ§Ù„ÙŠØ©.\n` +
            `Ø¢Ø®Ø± Ø®Ø·Ø£: ${errorMsg}${serverHealthInfo}\n` +
            `Ù…Ø¹Ø±Ù Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ø²ÙˆØ¯: ${providerJobId}\n` +
            `Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù‚ØªØ±Ø­: ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø³ÙŠØ±ÙØ± ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Hugging Face`;

          logError(`ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„ÙØ´Ù„ - Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ù‡Ù…Ø© ${jobId}`, failMsg);

          if (mergeStep?.id) {
            await supabase
              .from("job_steps")
              .update({
                status: "failed",
                error_message: failMsg,
                completed_at: new Date().toISOString(),
                output_data: {
                  ...(mergeOutput || {}),
                  consecutive_failures: newFailures,
                  max_failures_reached: true,
                  final_error: failMsg,
                },
              })
              .eq("id", mergeStep.id);
          }

          await supabase
            .from("jobs")
            .update({ status: "failed", error_message: failMsg })
            .eq("id", jobId);
        }
      }

      // Refresh after tick
      const refreshedJob = await supabase.from("jobs").select("*").eq("id", jobId).maybeSingle();
      if (refreshedJob.data) {
        Object.assign(job, {
          status: refreshedJob.data.status,
          progress: refreshedJob.data.progress,
          output_url: refreshedJob.data.output_url,
          error_message: refreshedJob.data.error_message,
          updated_at: refreshedJob.data.updated_at,
        });
      }

      const refreshedSteps = await supabase
        .from("job_steps")
        .select("*")
        .eq("job_id", jobId)
        .order("step_order");
      if (refreshedSteps.data) steps = refreshedSteps.data;
    }

    // Build logs
    const logs: Array<{
      step: string;
      status: string;
      message: string;
      duration_ms?: number;
      started_at?: string;
      completed_at?: string;
      output_data?: unknown;
      error?: string;
    }> = [];

    for (const step of steps || []) {
      let duration_ms: number | undefined;
      if (step.started_at && step.completed_at) {
        duration_ms = new Date(step.completed_at).getTime() - new Date(step.started_at).getTime();
      }

      let message = "";
      switch (step.status) {
        case "pending":
          message = `â³ ${step.step_name} ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø¨Ø¯Ø¡`;
          break;
        case "processing":
          message = `ğŸ”„ ${step.step_name} Ø¬Ø§Ø±Ù Ø§Ù„ØªÙ†ÙÙŠØ°...`;
          break;
        case "completed":
          message = `âœ… ${step.step_name} Ø§ÙƒØªÙ…Ù„${duration_ms ? ` (${(duration_ms / 1000).toFixed(1)}s)` : ""}`;
          break;
        case "failed":
          message = `âŒ ${step.step_name} ÙØ´Ù„: ${step.error_message || "Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"}`;
          break;
        default:
          message = step.step_name;
      }

      logs.push({
        step: step.step_name,
        status: step.status,
        message,
        duration_ms,
        started_at: step.started_at,
        completed_at: step.completed_at,
        output_data: step.output_data,
        error: step.error_message || undefined,
      });
    }

    // Stuck detection with enhanced diagnostics
    let isStuck = false;
    let stuckWarning: string | undefined;
    let stuckDiagnostics: any = undefined;

    if (job.status === "processing") {
      const processingStep = (steps || []).find((s: any) => s.status === "processing");
      if (processingStep?.started_at) {
        const processingDuration = Date.now() - new Date(processingStep.started_at).getTime();
        if (processingDuration > 3 * 60 * 1000) {
          isStuck = true;
          const minutesStuck = Math.floor(processingDuration / 60000);
          
          stuckWarning = `Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù…ØªØ¹Ø·Ù„Ø© Ù…Ù†Ø° ${minutesStuck} Ø¯Ù‚ÙŠÙ‚Ø© ÙÙŠ Ø®Ø·ÙˆØ© "${processingStep.step_name}"`;
          
          // Get server health for diagnostics
          try {
            const healthCheck = await isFFmpegSpaceHealthy();
            stuckDiagnostics = {
              stuck_duration_minutes: minutesStuck,
              stuck_step: processingStep.step_name,
              server_healthy: healthCheck.healthy,
              server_status: healthCheck.status,
              server_error: healthCheck.error,
              is_sleeping: healthCheck.isSleeping,
              suggestion: healthCheck.isSleeping 
                ? "Ø§Ù„Ø³ÙŠØ±ÙØ± ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø³ÙƒÙˆÙ† - Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©"
                : !healthCheck.healthy
                  ? "Ø§Ù„Ø³ÙŠØ±ÙØ± ØºÙŠØ± Ù…ØªØ§Ø­ - ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„ØªÙ‡ Ø¹Ù„Ù‰ Hugging Face"
                  : "Ø§Ù„Ù…Ù‡Ù…Ø© Ø¹Ø§Ù„Ù‚Ø© Ø±ØºÙ… Ø£Ù† Ø§Ù„Ø³ÙŠØ±ÙØ± ÙŠØ¹Ù…Ù„ - Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ù„Ù„Ø¥Ù„ØºØ§Ø¡ ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©"
            };
          } catch (healthError) {
            stuckDiagnostics = {
              stuck_duration_minutes: minutesStuck,
              stuck_step: processingStep.step_name,
              health_check_failed: true,
              error: healthError instanceof Error ? healthError.message : String(healthError)
            };
          }

          logWarning(`Ø§Ù„Ù…Ù‡Ù…Ø© ${jobId} Ø¹Ø§Ù„Ù‚Ø©`, stuckDiagnostics);
        }
      }
    }

    const response = {
      job_id: job.id,
      type: job.type,
      status: job.status,
      progress: job.progress,
      output_url: job.output_url,
      error_message: job.error_message,
      created_at: job.created_at,
      updated_at: job.updated_at,
      logs,
      is_stuck: isStuck,
      stuck_warning: stuckWarning,
      stuck_diagnostics: stuckDiagnostics,
      is_complete: job.status === "completed",
      is_failed: job.status === "failed",
      can_cancel: job.status === "pending" || job.status === "processing",
    };

    logInfo(`Ø¥Ø±Ø¬Ø§Ø¹ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø© ${jobId}`, {
      status: job.status,
      progress: job.progress,
      hasOutput: !!job.output_url,
      isStuck
    });

    return new Response(
      JSON.stringify(response),
      { headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  } catch (err) {
    const error = err instanceof Error ? err : new Error(String(err));
    logError("Ø®Ø·Ø£ ÙÙŠ job-status", error);
    
    return new Response(
      JSON.stringify({ 
        error: error.message,
        timestamp: new Date().toISOString(),
        type: 'internal_error'
      }),
      { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  }
});
